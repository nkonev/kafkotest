#logging.level.org.springframework.kafka.listener: DEBUG
management:
  endpoints:
    web:
      exposure:
        include: '*'

spring:
  kafka:
#    consumer:
#      group-id: group-id
#      auto-offset-reset: earliest
#      key-deserializer: org.apache.kafka.common.serialization.StringDeserializer
#      value-deserializer: org.springframework.kafka.support.serializer.JsonDeserializer
#      properties:
#        # https://kafka.apache.org/documentation/#configuration
#        spring.json.trusted.packages: io.tpd.kafkaexample
#        isolation.level: read_committed
#        enable.auto.commit: false
#        # increase batch consuming: set max.poll.records
#        max.poll.records: 8000
#    producer:
#      key-serializer: org.apache.kafka.common.serialization.StringSerializer
#      value-serializer: org.springframework.kafka.support.serializer.JsonSerializer
#      transaction-id-prefix: ${spring.cloud.client.ip-address}_tx.
#      properties:
#        # for ordering
#        max.in.flight.requests.per.connection: 1
#        enable.idempotence: true
#        # retries: 10000
#        delivery.timeout.ms: 300000 # 5 minutes
#        retry.backoff.ms: 1000
#        acks: all
#        #transactional.id: producer-1
#    bootstrap-servers: localhost:19092
#    # https://docs.spring.io/spring-boot/docs/current/reference/htmlsingle/#common-application-properties
#    listener:
#      # increase batch consuming: set type=batch
#      type: batch
#      ack-mode: batch
#      # increase batch consuming: set poll-timeout
#      poll-timeout: 10s


  cloud:
    stream:
      kafka:
        bindings:
          input:
            consumer:
              # KafkaMessageChannelBinder.createConsumerEndpoint(extendedConsumerProperties)
              pollTimeout: 10000
          output:
            producer:
              bufferSize: 163840
              batchTimeout: 10000
        binder:
          consumerProperties:
            spring.json.trusted.packages: '*'
            isolation.level: read_committed
            enable.auto.commit: false
            # increase batch consuming: set max.poll.records
            max.poll.records: 8000
            auto.offset.reset: earliest
            key.deserializer: org.apache.kafka.common.serialization.StringDeserializer
            value.deserializer: org.springframework.kafka.support.serializer.JsonDeserializer
#            min.fetch.bytes: 100000
#            fetch.max.wait.ms: 30000
          producerProperties:
            key.serializer: org.apache.kafka.common.serialization.StringSerializer
            value.serializer: org.springframework.kafka.support.serializer.JsonSerializer
          configuration:
            auto.offset.reset: earliest
          brokers: localhost
          defaultBrokerPort: 19092
          transaction:
            producer:
#              sync: true
#              batchTimeout: 30000
              #bufferSize: 163840
              #batchTimeout: 20000
              configuration:
                # for ordering
                max.in.flight.requests.per.connection: 1
                enable.idempotence: true
                retries: 10000
                delivery.timeout.ms: 300000 # 5 minutes
                retry.backoff.ms: 1000
                acks: all
            transactionIdPrefix: ${spring.cloud.client.ip-address}_tx.
          autoAddPartitions: true
          autoCreateTopics: true
#          requiredAcks: all
      bindings:
        input:
          destination: thing1
          group: my-group-id
          maxAttempts: 1
          consumer:
            batch-mode: true
            #configuration:
            maxAttempts: 1
            useNativeDecoding: true

        output:
          destination: thing1
          producer:
            useNativeEncoding: true
#            configuration:


tpd:
  topic-name: advice-topic
